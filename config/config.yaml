mode: train  # "train" or "eval"

data:
  dataset_name: ag_news
  batch_size: 64
  max_seq_len: 128
  val_split: 0.1

model:
  type: dnn  # you can later switch to "lstm" or "transformer"
  embedding_dim: 100
  hidden_dim: 256
  dropout: 0.3
  num_classes: 4

training:
  epochs: 15
  patience: 5
  lr: 0.0010
  weight_decay: 0.0001

misc:
  save_dir: "checkpoints"
  model_file: "saved_model.pt"
  vocab_file: "vocab.pkl"
  seed: 42
